{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importación de librerías \n",
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abraham/TT/my_tensorflow/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/abraham/TT/my_tensorflow/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/abraham/TT/my_tensorflow/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/abraham/TT/my_tensorflow/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/abraham/TT/my_tensorflow/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/abraham/TT/my_tensorflow/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/abraham/TT/my_tensorflow/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/abraham/TT/my_tensorflow/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/abraham/TT/my_tensorflow/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/abraham/TT/my_tensorflow/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/abraham/TT/my_tensorflow/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/abraham/TT/my_tensorflow/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/abraham/TT/my_tensorflow/imgdetect-utils\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(24, 32)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import ntpath\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Change this with the directory where you cloned the imgdetect-utils repo\n",
    "basedir = os.path.join(os.path.expanduser('~'), 'TT', 'my_tensorflow', 'imgdetect-utils' )\n",
    "sys.path.append(os.path.join(basedir))\n",
    "\n",
    "print (basedir)\n",
    "\n",
    "from src.image_helpers import plot_images_grid, create_dataset_files\n",
    "from src.train_helpers import load_data, plot_results, export_model\n",
    "\n",
    "# The Tensorflow model and properties file will be stored here\n",
    "tf_model_dir = os.path.join(basedir, 'models', 'ir', 'tensorflow')\n",
    "tf_model_file = os.path.join(tf_model_dir, 'ir.pb')\n",
    "tf_properties_file = os.path.join(tf_model_dir, 'ir.json')\n",
    "\n",
    "# Base directory that contains your training images and dataset files\n",
    "dataset_base_dir = os.path.join(basedir, 'datasets', 'ir')\n",
    "dataset_dir = os.path.join(dataset_base_dir, 'data')\n",
    "\n",
    "# Store your thermal camera images here\n",
    "img_dir = os.path.join(dataset_base_dir, 'images')\n",
    "\n",
    "# Size of the input images\n",
    "input_size = (24, 32)\n",
    "input_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Creación de directorios de modelos\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.makedirs(tf_model_dir, mode=0o775, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creación de un dataset por las imagenes disponibles\n",
    "------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 485 images to 1 dataset files. Format: /home/abraham/TT/my_tensorflow/imgdetect-utils/datasets/ir/data/dataset{:01}.npz\n",
      "Storing dataset vectors to /home/abraham/TT/my_tensorflow/imgdetect-utils/datasets/ir/data/dataset0.npz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/abraham/TT/my_tensorflow/imgdetect-utils/datasets/ir/data/dataset0.npz']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_files = create_dataset_files(img_dir, dataset_dir,\n",
    "                                     split_size=1000,\n",
    "                                     num_threads=1,\n",
    "                                     resize=input_size)\n",
    "dataset_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar el dataset\n",
    "------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/abraham/TT/my_tensorflow/imgdetect-utils/datasets/ir/data/dataset0.npz']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_files = [os.path.join(dataset_dir, f)\n",
    "                 for f in os.listdir(dataset_dir)\n",
    "                 if os.path.isfile(os.path.join(dataset_dir, f))\n",
    "                 and f.endswith('.npz')]\n",
    "\n",
    "dataset_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividir el set de datos con distribución 70/30\n",
    "-------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 339 training images and 146 test images. Classes: ['negative' 'positive']\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set, classes = load_data(*dataset_files, split_percentage=0.7)\n",
    "print('Loaded {} training images and {} test images. Classes: {}'.format(\n",
    "    train_set.shape[0], test_set.shape[0], classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_images = np.asarray([item[0] for item in train_set])\n",
    "train_labels = np.asarray([item[1] for item in train_set])\n",
    "test_images = np.asarray([item[0] for item in test_set])\n",
    "test_labels = np.asarray([item[1] for item in test_set])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declaración del modelo\n",
    "-----------------\n",
    "\n",
    "* Flatten input\n",
    "* Layer 1: 60% the number of pixels per image\n",
    "* Layer 2: 30% the number of pixels per image\n",
    "* Layer 3: as many neurons as the output labels (in this case 2: negative, positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/abraham/TT/my_tensorflow/venv/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=train_images[0].shape),\n",
    "    keras.layers.Dense(int(0.6 * train_images.shape[1] * train_images.shape[2]), activation=tf.nn.relu),\n",
    "    keras.layers.Dense(int(0.3 * train_images.shape[1] * train_images.shape[2]), activation=tf.nn.relu),\n",
    "    keras.layers.Dense(len(classes), activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model\n",
    "-----------------\n",
    "\n",
    "- *Loss function*:This measures how accurate the model is during training. We want to minimize this function to \"steer\" the model in the right direction.\n",
    "- *Optimizer*: This is how the model is updated based on the data it sees and its loss function.\n",
    "- *Metrics*: Used to monitor the training and testing steps. The following example uses accuracy, the fraction of the images that are correctly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento\n",
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "339/339 [==============================] - 0s 474us/sample - loss: 1.9868 - acc: 0.5192\n",
      "Epoch 2/100\n",
      "339/339 [==============================] - 0s 143us/sample - loss: 0.7952 - acc: 0.5103\n",
      "Epoch 3/100\n",
      "339/339 [==============================] - 0s 128us/sample - loss: 0.7177 - acc: 0.5664\n",
      "Epoch 4/100\n",
      "339/339 [==============================] - 0s 132us/sample - loss: 0.7380 - acc: 0.5723\n",
      "Epoch 5/100\n",
      "339/339 [==============================] - 0s 135us/sample - loss: 0.7048 - acc: 0.5133\n",
      "Epoch 6/100\n",
      "339/339 [==============================] - 0s 122us/sample - loss: 0.6697 - acc: 0.5457\n",
      "Epoch 7/100\n",
      "339/339 [==============================] - 0s 122us/sample - loss: 0.6554 - acc: 0.5251\n",
      "Epoch 8/100\n",
      "339/339 [==============================] - 0s 122us/sample - loss: 0.6672 - acc: 0.5693\n",
      "Epoch 9/100\n",
      "339/339 [==============================] - 0s 144us/sample - loss: 0.6356 - acc: 0.5516\n",
      "Epoch 10/100\n",
      "339/339 [==============================] - 0s 119us/sample - loss: 0.5329 - acc: 0.8201\n",
      "Epoch 11/100\n",
      "339/339 [==============================] - 0s 122us/sample - loss: 0.5049 - acc: 0.7758\n",
      "Epoch 12/100\n",
      "339/339 [==============================] - 0s 130us/sample - loss: 0.4409 - acc: 0.8555\n",
      "Epoch 13/100\n",
      "339/339 [==============================] - 0s 118us/sample - loss: 0.3693 - acc: 0.9056\n",
      "Epoch 14/100\n",
      "339/339 [==============================] - 0s 119us/sample - loss: 0.4016 - acc: 0.8466\n",
      "Epoch 15/100\n",
      "339/339 [==============================] - 0s 121us/sample - loss: 0.5543 - acc: 0.6844\n",
      "Epoch 16/100\n",
      "339/339 [==============================] - 0s 130us/sample - loss: 0.4805 - acc: 0.7050\n",
      "Epoch 17/100\n",
      "339/339 [==============================] - 0s 118us/sample - loss: 0.3424 - acc: 0.8968\n",
      "Epoch 18/100\n",
      "339/339 [==============================] - 0s 128us/sample - loss: 0.3155 - acc: 0.8938\n",
      "Epoch 19/100\n",
      "339/339 [==============================] - 0s 118us/sample - loss: 0.2859 - acc: 0.8761\n",
      "Epoch 20/100\n",
      "339/339 [==============================] - 0s 131us/sample - loss: 0.2616 - acc: 0.9027\n",
      "Epoch 21/100\n",
      "339/339 [==============================] - 0s 132us/sample - loss: 0.2759 - acc: 0.9322\n",
      "Epoch 22/100\n",
      "339/339 [==============================] - 0s 117us/sample - loss: 0.2839 - acc: 0.9145\n",
      "Epoch 23/100\n",
      "339/339 [==============================] - 0s 116us/sample - loss: 0.3023 - acc: 0.8938\n",
      "Epoch 24/100\n",
      "339/339 [==============================] - 0s 124us/sample - loss: 0.3074 - acc: 0.8879\n",
      "Epoch 25/100\n",
      "339/339 [==============================] - 0s 114us/sample - loss: 0.3230 - acc: 0.8702\n",
      "Epoch 26/100\n",
      "339/339 [==============================] - 0s 116us/sample - loss: 0.2835 - acc: 0.8820\n",
      "Epoch 27/100\n",
      "339/339 [==============================] - 0s 116us/sample - loss: 0.2242 - acc: 0.9410\n",
      "Epoch 28/100\n",
      "339/339 [==============================] - 0s 116us/sample - loss: 0.2362 - acc: 0.9263\n",
      "Epoch 29/100\n",
      "339/339 [==============================] - 0s 115us/sample - loss: 0.2270 - acc: 0.9145\n",
      "Epoch 30/100\n",
      "339/339 [==============================] - 0s 118us/sample - loss: 0.3094 - acc: 0.8525\n",
      "Epoch 31/100\n",
      "339/339 [==============================] - 0s 117us/sample - loss: 0.2060 - acc: 0.9263\n",
      "Epoch 32/100\n",
      "339/339 [==============================] - 0s 126us/sample - loss: 0.2221 - acc: 0.9410\n",
      "Epoch 33/100\n",
      "339/339 [==============================] - 0s 117us/sample - loss: 0.1918 - acc: 0.9322\n",
      "Epoch 34/100\n",
      "339/339 [==============================] - 0s 117us/sample - loss: 0.1769 - acc: 0.9440\n",
      "Epoch 35/100\n",
      "339/339 [==============================] - 0s 116us/sample - loss: 0.1759 - acc: 0.9351\n",
      "Epoch 36/100\n",
      "339/339 [==============================] - 0s 120us/sample - loss: 0.1802 - acc: 0.9440\n",
      "Epoch 37/100\n",
      "339/339 [==============================] - 0s 116us/sample - loss: 0.1608 - acc: 0.9469\n",
      "Epoch 38/100\n",
      "339/339 [==============================] - 0s 117us/sample - loss: 0.1564 - acc: 0.9558\n",
      "Epoch 39/100\n",
      "339/339 [==============================] - 0s 131us/sample - loss: 0.1665 - acc: 0.9440\n",
      "Epoch 40/100\n",
      "339/339 [==============================] - 0s 133us/sample - loss: 0.1661 - acc: 0.9440\n",
      "Epoch 41/100\n",
      "339/339 [==============================] - 0s 133us/sample - loss: 0.2439 - acc: 0.9233\n",
      "Epoch 42/100\n",
      "339/339 [==============================] - 0s 128us/sample - loss: 0.1781 - acc: 0.9381\n",
      "Epoch 43/100\n",
      "339/339 [==============================] - 0s 127us/sample - loss: 0.1507 - acc: 0.9528\n",
      "Epoch 44/100\n",
      "339/339 [==============================] - 0s 124us/sample - loss: 0.1584 - acc: 0.9499\n",
      "Epoch 45/100\n",
      "339/339 [==============================] - 0s 129us/sample - loss: 0.2001 - acc: 0.9322\n",
      "Epoch 46/100\n",
      "339/339 [==============================] - 0s 118us/sample - loss: 0.2924 - acc: 0.8909\n",
      "Epoch 47/100\n",
      "339/339 [==============================] - 0s 119us/sample - loss: 0.2772 - acc: 0.9056\n",
      "Epoch 48/100\n",
      "339/339 [==============================] - 0s 118us/sample - loss: 0.1884 - acc: 0.9410\n",
      "Epoch 49/100\n",
      "339/339 [==============================] - 0s 118us/sample - loss: 0.1603 - acc: 0.9558\n",
      "Epoch 50/100\n",
      "339/339 [==============================] - 0s 120us/sample - loss: 0.2084 - acc: 0.9145\n",
      "Epoch 51/100\n",
      "339/339 [==============================] - 0s 120us/sample - loss: 0.1656 - acc: 0.9587\n",
      "Epoch 52/100\n",
      "339/339 [==============================] - 0s 120us/sample - loss: 0.1659 - acc: 0.9558\n",
      "Epoch 53/100\n",
      "339/339 [==============================] - 0s 118us/sample - loss: 0.3251 - acc: 0.8407\n",
      "Epoch 54/100\n",
      "339/339 [==============================] - 0s 120us/sample - loss: 0.3822 - acc: 0.8260\n",
      "Epoch 55/100\n",
      "339/339 [==============================] - 0s 125us/sample - loss: 0.2166 - acc: 0.9204\n",
      "Epoch 56/100\n",
      "339/339 [==============================] - 0s 117us/sample - loss: 0.1631 - acc: 0.9587\n",
      "Epoch 57/100\n",
      "339/339 [==============================] - 0s 115us/sample - loss: 0.1507 - acc: 0.9587\n",
      "Epoch 58/100\n",
      "339/339 [==============================] - 0s 115us/sample - loss: 0.1793 - acc: 0.9499\n",
      "Epoch 59/100\n",
      "339/339 [==============================] - 0s 115us/sample - loss: 0.1404 - acc: 0.9587\n",
      "Epoch 60/100\n",
      "339/339 [==============================] - 0s 116us/sample - loss: 0.2093 - acc: 0.9204\n",
      "Epoch 61/100\n",
      "339/339 [==============================] - 0s 116us/sample - loss: 0.1629 - acc: 0.9558\n",
      "Epoch 62/100\n",
      "339/339 [==============================] - 0s 117us/sample - loss: 0.2082 - acc: 0.9351\n",
      "Epoch 63/100\n",
      "339/339 [==============================] - 0s 122us/sample - loss: 0.2254 - acc: 0.9351\n",
      "Epoch 64/100\n",
      "339/339 [==============================] - 0s 132us/sample - loss: 0.1633 - acc: 0.9469\n",
      "Epoch 65/100\n",
      "339/339 [==============================] - 0s 136us/sample - loss: 0.1352 - acc: 0.9705\n",
      "Epoch 66/100\n",
      "339/339 [==============================] - 0s 139us/sample - loss: 0.1297 - acc: 0.9676\n",
      "Epoch 67/100\n",
      "339/339 [==============================] - 0s 138us/sample - loss: 0.1424 - acc: 0.9587\n",
      "Epoch 68/100\n",
      "339/339 [==============================] - 0s 128us/sample - loss: 0.1871 - acc: 0.9322\n",
      "Epoch 69/100\n",
      "339/339 [==============================] - 0s 116us/sample - loss: 0.1254 - acc: 0.9646\n",
      "Epoch 70/100\n",
      "339/339 [==============================] - 0s 116us/sample - loss: 0.1377 - acc: 0.9676\n",
      "Epoch 71/100\n",
      "339/339 [==============================] - 0s 116us/sample - loss: 0.1416 - acc: 0.9676\n",
      "Epoch 72/100\n",
      "339/339 [==============================] - 0s 116us/sample - loss: 0.1351 - acc: 0.9646\n",
      "Epoch 73/100\n",
      "339/339 [==============================] - 0s 119us/sample - loss: 0.1288 - acc: 0.9735\n",
      "Epoch 74/100\n",
      "339/339 [==============================] - 0s 119us/sample - loss: 0.1734 - acc: 0.9499\n",
      "Epoch 75/100\n",
      "339/339 [==============================] - 0s 121us/sample - loss: 0.2488 - acc: 0.9115\n",
      "Epoch 76/100\n",
      "339/339 [==============================] - 0s 115us/sample - loss: 0.1700 - acc: 0.9528\n",
      "Epoch 77/100\n",
      "339/339 [==============================] - 0s 115us/sample - loss: 0.1478 - acc: 0.9617\n",
      "Epoch 78/100\n",
      "339/339 [==============================] - 0s 116us/sample - loss: 0.1406 - acc: 0.9617\n",
      "Epoch 79/100\n",
      "339/339 [==============================] - 0s 129us/sample - loss: 0.1246 - acc: 0.9646\n",
      "Epoch 80/100\n",
      "339/339 [==============================] - 0s 134us/sample - loss: 0.1323 - acc: 0.9646\n",
      "Epoch 81/100\n",
      "339/339 [==============================] - 0s 125us/sample - loss: 0.1272 - acc: 0.9587\n",
      "Epoch 82/100\n",
      "339/339 [==============================] - 0s 117us/sample - loss: 0.1317 - acc: 0.9646\n",
      "Epoch 83/100\n",
      "339/339 [==============================] - 0s 116us/sample - loss: 0.1356 - acc: 0.9705\n",
      "Epoch 84/100\n",
      "339/339 [==============================] - 0s 114us/sample - loss: 0.1366 - acc: 0.9587\n",
      "Epoch 85/100\n",
      "339/339 [==============================] - 0s 115us/sample - loss: 0.1233 - acc: 0.9705\n",
      "Epoch 86/100\n",
      "339/339 [==============================] - 0s 116us/sample - loss: 0.1235 - acc: 0.9735\n",
      "Epoch 87/100\n",
      "339/339 [==============================] - 0s 114us/sample - loss: 0.1939 - acc: 0.9381\n",
      "Epoch 88/100\n",
      "339/339 [==============================] - 0s 115us/sample - loss: 0.2433 - acc: 0.9056\n",
      "Epoch 89/100\n",
      "339/339 [==============================] - 0s 115us/sample - loss: 0.1542 - acc: 0.9499\n",
      "Epoch 90/100\n",
      "339/339 [==============================] - 0s 114us/sample - loss: 0.1840 - acc: 0.9351\n",
      "Epoch 91/100\n",
      "339/339 [==============================] - 0s 128us/sample - loss: 0.1829 - acc: 0.9469\n",
      "Epoch 92/100\n",
      "339/339 [==============================] - 0s 128us/sample - loss: 0.1991 - acc: 0.9351\n",
      "Epoch 93/100\n",
      "339/339 [==============================] - 0s 116us/sample - loss: 0.1448 - acc: 0.9617\n",
      "Epoch 94/100\n",
      "339/339 [==============================] - 0s 121us/sample - loss: 0.1307 - acc: 0.9646\n",
      "Epoch 95/100\n",
      "339/339 [==============================] - 0s 116us/sample - loss: 0.1509 - acc: 0.9587\n",
      "Epoch 96/100\n",
      "339/339 [==============================] - 0s 114us/sample - loss: 0.2122 - acc: 0.9263\n",
      "Epoch 97/100\n",
      "339/339 [==============================] - 0s 114us/sample - loss: 0.1511 - acc: 0.9646\n",
      "Epoch 98/100\n",
      "339/339 [==============================] - 0s 114us/sample - loss: 0.1301 - acc: 0.9646\n",
      "Epoch 99/100\n",
      "339/339 [==============================] - 0s 114us/sample - loss: 0.1291 - acc: 0.9617\n",
      "Epoch 100/100\n",
      "339/339 [==============================] - 0s 114us/sample - loss: 0.1416 - acc: 0.9646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7c1daedac8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluación de precisión en comparación con el dataset\n",
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 0s 145us/sample - loss: 0.1396 - acc: 0.9726\n",
      "Test accuracy: 0.9726027\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exportar modelo Tensorflow\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/abraham/TT/my_tensorflow/imgdetect-utils/src/train_helpers.py:117: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/abraham/TT/my_tensorflow/imgdetect-utils/src/train_helpers.py:170: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/abraham/TT/my_tensorflow/imgdetect-utils/src/train_helpers.py:180: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From /home/abraham/TT/my_tensorflow/venv/lib/python3.7/site-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 23 variables.\n",
      "INFO:tensorflow:Converted 23 variables to const ops.\n",
      "WARNING:tensorflow:From /home/abraham/TT/my_tensorflow/imgdetect-utils/src/train_helpers.py:119: The name tf.train.write_graph is deprecated. Please use tf.io.write_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "export_model(model, tf_model_file,\n",
    "             properties_file=tf_properties_file,\n",
    "             classes=classes,\n",
    "             input_size=input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
